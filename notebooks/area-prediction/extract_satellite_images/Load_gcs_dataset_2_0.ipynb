{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyPL6s8e4W7S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import ee\n",
        "import pandas as pd\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = storage.Client()\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='wildfire-lab')\n",
        "fires = pd.read_csv(\"request_data.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "ANfc2n1M4cV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fires = pd.read_csv(\"request_data.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "8M4qg1L1TOQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket = \"wildfire-lab\"\n",
        "folder = \"batch_export_0422_test_3\""
      ],
      "metadata": {
        "id": "kBGvK_pl4wrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operational data"
      ],
      "metadata": {
        "id": "67-c2QdAYJqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"operational_table.csv\", index_col=0)\n",
        "df['next_area_diff'] = df.groupby('id')['area_diff'].shift(-1)\n",
        "df = df.dropna(subset=['next_area_diff'])\n",
        "df = df[df['day_since_first_report']<21]"
      ],
      "metadata": {
        "id": "Wbxxv1_FwEEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, dataframe, features_path):\n",
        "        self.dataframe = dataframe\n",
        "        self.preloaded_images = {}\n",
        "        with open(features_path, \"rb\") as f:\n",
        "            self.features_dict = pickle.load(f)\n",
        "        self._preload_images()\n",
        "        self.number_features = dataframe.iloc[0].drop(['export_index', 'report_id', 'id', 'next_area_diff']).shape[0]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.preloaded_images)\n",
        "\n",
        "    def __getitem__(self, idx): #idx = idx in dataframe\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        features = torch.tensor(row.drop(['export_index', 'report_id', 'id', 'next_area_diff']).values.astype(float), dtype=torch.float)\n",
        "        target = torch.tensor(row['next_area_diff'], dtype=torch.float)\n",
        "        images_key = (row['id'], int(row['day_since_first_report']))\n",
        "        images_tensor = self.preloaded_images.get(images_key, torch.zeros(7, 64, 64, dtype=torch.float))\n",
        "        return features, images_tensor, target\n",
        "\n",
        "    def _preload_images(self):\n",
        "        for index, row in tqdm(self.dataframe.iterrows(), total=self.dataframe.shape[0]):\n",
        "            fire_id = row['id']\n",
        "            day_since_first_report = row['day_since_first_report']\n",
        "            pattern = r'[^a-zA-Z0-9.,:_;-]'\n",
        "            cleaned_fire_id = re.sub(pattern, '', fire_id)\n",
        "            tfrecord_path = f\"gs://{bucket}/{folder}/{cleaned_fire_id}.tfrecord.gz\"\n",
        "            try:\n",
        "              self.preloaded_images[(fire_id, int(day_since_first_report))] = self.load_and_parse_tfrecord(tfrecord_path, day_since_first_report)\n",
        "            except:\n",
        "              try:\n",
        "                pattern = r'[^a-zA-Z0-9.,:_; -]'\n",
        "                cleaned_fire_id = re.sub(pattern, '', fire_id)\n",
        "\n",
        "                tfrecord_path = f\"gs://{bucket}/{folder}/{cleaned_fire_id}.tfrecord.gz\"\n",
        "                self.preloaded_images[(fire_id, int(day_since_first_report))] = self.load_and_parse_tfrecord(tfrecord_path, day_since_first_report)\n",
        "              except:\n",
        "                print(tfrecord_path, \"not found in GCS\")\n",
        "    def load_and_parse_tfrecord(self, tfrecord_path, day_since_first_report):\n",
        "        layers = ['pr', 'sph', 'th', 'tmmn', 'tmmx', 'vs', 'erc']\n",
        "        day = f\"{int(day_since_first_report):02}\"\n",
        "        images_array = np.zeros((7, 64, 64))\n",
        "        try:\n",
        "          raw_dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='GZIP')\n",
        "          for raw_record in raw_dataset.take(1): # one record per dataset\n",
        "              example = tf.io.parse_single_example(raw_record, self.features_dict)\n",
        "              for i, layer in enumerate(layers):\n",
        "                  key = f'{day}_{layer}'\n",
        "                  if key in example:\n",
        "                      images_array[i] = example[key].numpy()\n",
        "                  else:\n",
        "                      print(f\"Key {key} not found in TFRecord.\")\n",
        "        except:\n",
        "          raise ValueError(\"Path not found\", tfrecord_path, day_since_first_report)\n",
        "\n",
        "        return  torch.tensor(images_array, dtype=torch.float)\n",
        "\n"
      ],
      "metadata": {
        "id": "43LVlDcy5QSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, dataframe, features_path):\n",
        "        self.dataframe = dataframe\n",
        "        self.features_dict = self._load_features(features_path)\n",
        "        self.preloaded_images = self._preload_images()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        features = self._extract_features(row)\n",
        "        target = torch.tensor(row['next_area_diff'], dtype=torch.float)\n",
        "        images_tensor = self.preloaded_images.get((row['id'], int(row['day_since_first_report'])), torch.zeros(7, 64, 64, dtype=torch.float))\n",
        "        return features, images_tensor, target\n",
        "\n",
        "    def _load_features(self, path):\n",
        "        with open(path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def _extract_features(self, row):\n",
        "        feature_cols = row.drop(['export_index', 'report_id', 'id', 'next_area_diff']).values.astype(float)\n",
        "        return torch.tensor(feature_cols, dtype=torch.float)\n",
        "\n",
        "    def _preload_images(self):\n",
        "        images = {}\n",
        "        for index, row in tqdm(self.dataframe.iterrows(), total=self.dataframe.shape[0]):\n",
        "            fire_id, day_since_first_report = row['id'], int(row['day_since_first_report'])\n",
        "            cleaned_fire_id = self._clean_id(fire_id)\n",
        "            tfrecord_path = self._construct_tfrecord_path(cleaned_fire_id)\n",
        "            images[(fire_id, day_since_first_report)] = self._load_image_data(tfrecord_path, day_since_first_report)\n",
        "        return images\n",
        "\n",
        "    def _clean_id(self, fire_id):\n",
        "        pattern = r'[^a-zA-Z0-9.,:_;-]'\n",
        "        return re.sub(pattern, '', fire_id)\n",
        "\n",
        "    def _construct_tfrecord_path(self, cleaned_fire_id):\n",
        "        return f\"gs://{bucket}/{folder}/{cleaned_fire_id}.tfrecord.gz\"\n",
        "\n",
        "    def _load_image_data(self, tfrecord_path, day_since_first_report):\n",
        "        layers = ['pr', 'sph', 'th', 'tmmn', 'tmmx', 'vs', 'erc']\n",
        "        day = f\"{day_since_first_report:02}\"\n",
        "        images_array = np.zeros((7, 64, 64))\n",
        "        try:\n",
        "            raw_dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='GZIP')\n",
        "            for raw_record in raw_dataset.take(1):  # one record per dataset\n",
        "                example = tf.io.parse_single_example(raw_record, self.features_dict)\n",
        "                for i, layer in enumerate(layers):\n",
        "                    key = f'{day}_{layer}'\n",
        "                    if key in example:\n",
        "                        images_array[i] = example[key].numpy()\n",
        "                    else:\n",
        "                        print(f\"Key {key} not found in TFRecord.\")\n",
        "        except:\n",
        "            raise ValueError(\"Path not found\", tfrecord_path, day_since_first_report)\n",
        "        return torch.tensor(images_array, dtype=torch.float)\n",
        "\n",
        "# Ensure that 'bucket' and 'folder' are defined somewhere in your code or passed as parameters to methods or constructors as needed.\n"
      ],
      "metadata": {
        "id": "MGdk75_0Xdm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, dataframe, features_path, bucket, folder):\n",
        "        self.dataframe = dataframe\n",
        "        self.preloaded_images = {}\n",
        "        self.bucket = bucket\n",
        "        self.folder = folder\n",
        "\n",
        "        with open(features_path, \"rb\") as f:\n",
        "            self.features_dict = pickle.load(f)\n",
        "\n",
        "        self._preload_images()\n",
        "        self.number_features = dataframe.iloc[0].drop(['export_index', 'report_id', 'id', 'next_area_diff'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.preloaded_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        features = torch.tensor(row.drop(['export_index', 'report_id', 'id', 'next_area_diff']).values.astype(float), dtype=torch.float)\n",
        "        target = torch.tensor(row['next_area_diff'], dtype=torch.float)\n",
        "        images_key = (row['id'], int(row['day_since_first_report']))\n",
        "        images_tensor = self.preloaded_images.get(images_key, torch.zeros(7, 64, 64, dtype=torch.float))\n",
        "        return features, images_tensor, target\n",
        "\n",
        "    def _preload_images(self):\n",
        "        for index, row in tqdm(self.dataframe.iterrows(), total=self.dataframe.shape[0]):\n",
        "            fire_id = row['id']\n",
        "            day_since_first_report = row['day_since_first_report']\n",
        "            cleaned_fire_id = self._clean_fire_id(fire_id)\n",
        "            tfrecord_path = self._get_tfrecord_path(cleaned_fire_id)\n",
        "\n",
        "            cleaned_fire_id2 = self._clean_fire_id2(fire_id)\n",
        "            tfrecord_path2 = self._get_tfrecord_path(cleaned_fire_id2)\n",
        "\n",
        "            try:\n",
        "                self.preloaded_images[(fire_id, int(day_since_first_report))] = self._load_and_parse_tfrecord(tfrecord_path, day_since_first_report)\n",
        "            except FileNotFoundError:\n",
        "              try:\n",
        "                self.preloaded_images[(fire_id, int(day_since_first_report))] = self._load_and_parse_tfrecord(tfrecord_path2, day_since_first_report)\n",
        "              except:\n",
        "                print(f\"TFRecord not found: {tfrecord_path}\\n{tfrecord_path2}\")\n",
        "\n",
        "    def _clean_fire_id(self, fire_id):\n",
        "        pattern = r'[^a-zA-Z0-9.,:_;-]'\n",
        "        return re.sub(pattern, '', fire_id)\n",
        "\n",
        "    def _clean_fire_id2(self, fire_id):\n",
        "        pattern = r'[^a-zA-Z0-9.,:_; -]'\n",
        "        return re.sub(pattern, '', fire_id)\n",
        "\n",
        "    def _get_tfrecord_path(self, cleaned_fire_id):\n",
        "        return f\"gs://{self.bucket}/{self.folder}/{cleaned_fire_id}.tfrecord.gz\"\n",
        "\n",
        "    def _load_and_parse_tfrecord(self, tfrecord_path, day_since_first_report):\n",
        "        layers = ['pr', 'sph', 'th', 'tmmn', 'tmmx', 'vs', 'erc']\n",
        "        day = f\"{int(day_since_first_report):02}\"\n",
        "        images_array = np.zeros((7, 64, 64))\n",
        "\n",
        "        try:\n",
        "            raw_dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='GZIP')\n",
        "            for raw_record in raw_dataset.take(1):\n",
        "                example = tf.io.parse_single_example(raw_record, self.features_dict)\n",
        "                for i, layer in enumerate(layers):\n",
        "                    key = f'{day}_{layer}'\n",
        "                    if key in example:\n",
        "                        images_array[i] = example[key].numpy()\n",
        "                    else:\n",
        "                        print(f\"Key {key} not found in TFRecord.\")\n",
        "        except:\n",
        "            raise FileNotFoundError(f\"TFRecord not found: {tfrecord_path}\")\n",
        "\n",
        "        return torch.tensor(images_array, dtype=torch.float)"
      ],
      "metadata": {
        "id": "O8KUbWOIXrQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = df\n",
        "folder = \"batch_export_0422_test_3\"\n",
        "features_path = \"/content/band_features.pkl\"\n",
        "dataset = FireDataset(dataframe,  features_path, bucket, folder)\n",
        "\n",
        "torch.save(obj=dataset, f=\"/content/drive/My Drive/RA/full_dataset.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HiA-RJ1wqMw",
        "outputId": "c7911e62-719c-45de-d098-2e68ca612395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25291/25291 [3:12:26<00:00,  2.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"gs://wildfire-lab/batch_export_0422_test_3/2015_2714081_BOOT COVE FIRE.tfrecord.gz\""
      ],
      "metadata": {
        "id": "lZNokJmbV8yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(features_path, \"rb\") as f:\n",
        "  features_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "mh_wI-NGWLFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_and_parse_tfrecord(tfrecord_path, day_since_first_report):\n",
        "      layers = ['pr', 'sph', 'th', 'tmmn', 'tmmx', 'vs', 'erc']\n",
        "      day = f\"{int(day_since_first_report):02}\"\n",
        "      images_array = np.zeros((7, 64, 64))\n",
        "      try:\n",
        "        raw_dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='GZIP')\n",
        "        for raw_record in raw_dataset.take(1): # one record per dataset\n",
        "            example = tf.io.parse_single_example(raw_record, features_dict)\n",
        "            for i, layer in enumerate(layers):\n",
        "                key = f'{day}_{layer}'\n",
        "                if key in example:\n",
        "                    images_array[i] = example[key].numpy()\n",
        "                else:\n",
        "                    print(f\"Key {key} not found in TFRecord.\")\n",
        "      except:\n",
        "        raise ValueError(\"Path not found\", tfrecord_path, day_since_first_report)\n",
        "      return  torch.tensor(images_array, dtype=torch.float)"
      ],
      "metadata": {
        "id": "WB_SVYfIWNs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPkr6jw59RlL",
        "outputId": "5a940675-c640-44f4-be82-c27f83434987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "feature_names = list(df.iloc[0].index[3:-8])\n",
        "\n",
        "def visualize_dataset_item(dataset, layer_names, feature_names, idx):\n",
        "    features, images_tensor, target = dataset[idx]\n",
        "    images_np = images_tensor.numpy()\n",
        "\n",
        "    fig, axs = plt.subplots(1, 9, figsize=(25, 3))  # 7 for the images, 1 for the features\n",
        "\n",
        "    # images\n",
        "    for i in range(images_np.shape[0]):\n",
        "        axs[i].imshow(images_np[i], cmap=plt.get_cmap('hot'))\n",
        "        axs[i].set_title(layer_names[i])\n",
        "        axs[i].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "    # one hot features\n",
        "    active_features = [feat for i, feat in enumerate(feature_names) if features[i]>0.1]\n",
        "    for i, feature in enumerate(active_features):\n",
        "        axs[7].text(0.1, 0.9-i*1/6, feature, fontsize=9)\n",
        "        axs[7].axis('off')\n",
        "        axs[7].set_title('Features')\n",
        "\n",
        "    axs[8].text(0.4, 0.5, target.item(), fontsize=15)\n",
        "    axs[8].axis('off')\n",
        "    axs[8].set_title('Diff area')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "layers = ['pr', 'sph', 'th', 'tmmn', 'tmmx', 'vs', 'erc']\n",
        "for i in range(50):\n",
        "  print(f\"Report index: {i}, fire id: {df.iloc[i].loc['id']}\")\n",
        "  visualize_dataset_item(dataset, layers, feature_names, i)\n"
      ],
      "metadata": {
        "id": "P_fmr04fYg1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.save(\"full_gee_dataset.pt\")"
      ],
      "metadata": {
        "id": "_QpUq84629Up"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}